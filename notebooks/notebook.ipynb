{
  "cells": [
    {
      "cell_type": "markdown",
      "source": "# Project 3: Image recognizion. (Melanoma)\n### Group 7: Emma, Laurits, Malthe, Mads og Jonas\n",
      "metadata": {
        "tags": [],
        "cell_id": "00000-07be400d-1a96-4a7d-882d-66f4480cd571",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "markdown",
      "source": "## Loading the Libraries",
      "metadata": {
        "tags": [],
        "cell_id": "00001-94edeab5-5e09-4f26-9176-4f9e7cb8b471",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00002-a8756e48-22e5-4dfe-8de7-1268ab1d28ca",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "503f43ae",
        "execution_millis": 26578,
        "execution_start": 1619173989620,
        "output_cleared": true,
        "deepnote_cell_type": "code"
      },
      "source": "## only applies when using deepnote\n!apt update\n!apt install ffmpeg libsm6 libxext6 -y\n\n!pip install opencv-python\n!pip install --upgrade pip",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00002-1a2f0d32-0af7-4d40-8553-20e881c36c1e",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "b68c7ea2",
        "execution_millis": 2365,
        "execution_start": 1619174016204,
        "output_cleared": true,
        "deepnote_cell_type": "code"
      },
      "source": "import numpy as np\nimport matplotlib.pyplot as plt\nimport os \nimport fyp2021p3_group00_functions as util\nimport pandas as pd\nimport cv2\nimport seaborn as sns\nimport math\n\nfrom skimage import morphology\nfrom skimage import filters\nfrom skimage.morphology import opening\nfrom skimage.color import label2rgb\nfrom skimage.segmentation import slic\nfrom skimage.segmentation import mark_boundaries\nfrom skimage.util import img_as_float\nfrom scipy.ndimage import rotate\nfrom skimage.exposure import is_low_contrast\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import preprocessing\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.gaussian_process import GaussianProcessClassifier\nfrom sklearn.gaussian_process.kernels import RBF\nfrom sklearn.decomposition import PCA",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "## Functions",
      "metadata": {
        "tags": [],
        "cell_id": "00003-3ef04e4d-5679-4eaa-ad42-5982c70f8a5e",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00004-1975218a-b0ce-4d72-a33a-94c154720b9b",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "52f0bc66",
        "execution_millis": 3,
        "execution_start": 1619174018572,
        "output_cleared": true,
        "deepnote_cell_type": "code"
      },
      "source": "def check_quality(dictionary_, image_id_jpg):\n    \"\"\" A Function that returns the number of pixels in an image that can\n    be used to check whether the image is low or high quality\"\"\"\n\n    im = plt.imread(dictionary_[image_id_jpg])\n    resolution = im.shape\n    num_of_pixels = resolution[0]*resolution[1]\n    return num_of_pixels",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00006-c7ddd2f6-656e-4b3a-982e-c0961439b836",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "cdd7de44",
        "execution_millis": 7,
        "execution_start": 1619174018578,
        "output_cleared": true,
        "deepnote_cell_type": "code"
      },
      "source": "def low_quality_pictures(resolution, dictionary_):\n    not_fine = 0\n    fine = 0\n    popped_image = []\n\n    for i in dictionary_:   \n        x = check_quality(dictionary_, str(i))\n        if x >= resolution:\n            fine += 1\n        else: \n            not_fine += 1\n            popped_image.append(i)\n\n    # then we pop the images from the dictionary PICTURES that are low quality \n    for i in popped_image:\n        if i in dictionary_:\n            dictionary_.pop(i)\n\n    print('Fine: {0}, Not fine: {1}'.format(fine, not_fine))\n    print('Image popped from the dict: {0}'.format(popped_image))",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00006-be2760ff-fd69-4b14-9183-963d8e11ffc6",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "749f68da",
        "execution_millis": 6,
        "execution_start": 1619174018587,
        "output_cleared": true,
        "deepnote_cell_type": "code"
      },
      "source": "def bluriness(dictionary_):\n    \n    \"\"\"This function takes a dictionary and checks whether the images\n    in the dictionary are blurry or sharp and then removes the blurry images\n    from the dictionary.\"\"\"\n\n    blurry_images = []\n    not_blurry = 0\n    blurry = 0\n    for key, value in dictionary_.items():   \n        x = cv2.imread(str(value))\n        v = cv2.Laplacian(x, cv2.CV_64F).var()\n        if v > 10:\n            not_blurry += 1\n        else: \n            blurry += 1\n            blurry_images.append(key)\n\n# now we delete the images from the dictionary that are blurry\n    for i in blurry_images:\n        dictionary_.pop(i)\n        temp = str(i)\n        dictionary_.pop(temp[:-4]+\"_segmentation.png\")\n\n    print('Not Blurry: {0}'.format(not_blurry))\n    print('Blurry: {0}'.format(blurry))\n    print(\"Blurry Images: {0}\".format(blurry_images))",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00008-992dacaf-7bfa-430d-9812-69244c5d5cf7",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "4967b90d",
        "execution_millis": 2,
        "execution_start": 1619174018599,
        "output_cleared": true,
        "deepnote_cell_type": "code"
      },
      "source": "def contrast(dictionary_):\n\n    \"\"\" The function takes a dictionary of images with the path as a value \n\tto input and checks the contrast of the image\"\"\"\n\n    high = 0\n    low = 0\n    low_ = []\n    for key, value in dictionary_.items():\n        x = cv2.imread(str(value))\n        y = is_low_contrast(x)\n        if y == True:\n            low += 1\n            low_.append(key)\n        else:\n            high += 1\n            \n    #Removes the low contrast from the PICTURES\n    for i in low_:\n        dictionary_.pop(i)\n\n    print('Number of Images with High Contrast: {0}'.format(high))\n    print('Number of Images with Low Contrast: {0}'.format(low))\n    print(\"Images with Low Contrast: {0}\".format(low_))",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00009-fa972df8-d118-4494-ab58-744efc6f73bb",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "22dd7c66",
        "execution_millis": 2,
        "execution_start": 1619174018605,
        "output_cleared": true,
        "deepnote_cell_type": "code"
      },
      "source": "def get_mask_size(mask):\n    \"\"\"Finding the min and max values for the mask\"\"\"\n    i, j = np.where(mask)\n\n    x_min = j.min()\n    x_max = j.max()\n    y_min = i.min()\n    y_max = i.max()\n    return x_min, x_max, y_min, y_max\n    ",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "def accuracy_matrix(prediction, answer):\n    \"\"\"Takes in the predictions of a model for a test-case, as well as the true values, \n    and returns a matrix of true and false for positive and negative cases.\"\"\"\n    total_sick = np.sum(answer)\n    total_healthy = len(answer)-total_sick\n    predictions_of_sick = [prediction == 1]\n    predictions_of_healthy = [prediction == 0]\n\n    helathy = [answer == 0]\n    sick = [answer == 1]\n\n    true_positive = len(answer[(prediction == 1) & (answer == 1)])/len(answer[answer == 1])\n    false_negative = 1-true_positive\n    true_negative = len(answer[(answer == 0) & (prediction == 0)])/len(answer[answer == 0])\n    false_positive = 1-true_negative\n\n    return true_positive, false_positive, true_negative, false_negative",
      "metadata": {
        "tags": [],
        "cell_id": "00010-4e319dc0-b7d0-4568-98a4-eab36e2437ee",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "8c5c0ca",
        "execution_millis": 5,
        "execution_start": 1619174018610,
        "output_cleared": true,
        "deepnote_cell_type": "code"
      },
      "outputs": [],
      "execution_count": 8
    },
    {
      "cell_type": "code",
      "source": "def make_knn_prediction(k):\n    \"\"\"This function takis in the number k in KNN-test, and trans using\n    the dataframes for training. With this model, it makes a prediction on the \n    test-data, and returns the prediction.\"\"\"\n    knn = KNeighborsClassifier(n_neighbors = k) #Create the model\n    knn.fit(df[['Asymmetry','Border', 'Colour']], df['illens']) #Train the model\n    answer = knn.predict(df_test[['Asymmetry','Border', 'Colour']]) #Use the model to predict\n    return answer",
      "metadata": {
        "tags": [],
        "cell_id": "00011-399a3fc1-5d65-4718-8425-cc574d0a4116",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "e548831f",
        "execution_millis": 0,
        "execution_start": 1619174018661,
        "output_cleared": true,
        "deepnote_cell_type": "code"
      },
      "outputs": [],
      "execution_count": 9
    },
    {
      "cell_type": "markdown",
      "source": "## Loading the data",
      "metadata": {
        "tags": [],
        "cell_id": "00004-4392844a-5173-4a9a-a8e7-2143ece5609b",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00005-6cd65a7a-98d6-45a3-9880-980e16c9e99b",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "eab25ed3",
        "execution_millis": 155,
        "output_cleared": true,
        "execution_start": 1619174018662,
        "deepnote_cell_type": "code"
      },
      "source": "# First we make the path to the data\nPATH = {}\nPATH[\"data\"] =\"../data\"\n\n#print(PATH)\n#Then we load the path for all the diffirent as keys to their names.\nPICTURES = {}\nfor path, subdirs, files in os.walk(PATH[\"data\"]):\n    for picture in files:\n        # Making sure that we exclude the .csv from the dictionary, to only include images (ie. png and jpg files)\n        if not str(picture).count(\".csv\", (len(picture) - 4),len(picture)):\n            PICTURES[picture] = os.path.normpath(os.path.join(path, picture))\n\nprint(PICTURES)\n# Remove a last file from the PICTURES dictonary\nPICTURES.pop(\".DS_Store\")\n\nimages = pd.read_csv(\"../data/example_ground_truth.csv\")\nimages['id'] = images['image_id']\nimage_way = pd.DataFrame.from_dict(PICTURES, orient='index')\nimage_way['id'] = image_way.index\nfor number, name in enumerate(iterable = image_way['id']):\n    image_way['id'][number] = name[0:12]\nimage_merge = images.merge(image_way, left_on ='image_id' , right_on = 'id', how = 'outer')\nimage_merge['healthy'] = 1-image_merge['melanoma']-image_merge['seborrheic_keratosis']\nimage_merge = image_merge.rename(columns ={0: 'path'})\nimage_merge['mask'] = image_merge['path'].str.contains('png')\nimage_merge['raw'] = image_merge['path'].str.contains('jpg')\n# Reworking images to contain name and helath of all the images to use later.\nimages = images.dropna(axis=0)\nimages = images[images['seborrheic_keratosis']!= 1]\n",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "# Task 0: Explore the Data\n\nGo through the data (csv file, images, segmentations) that you have available\nto understand what’s available to you, and write a brief description. Decide if\nthis data is sufficient, or if cleaning is needed. For example, what do you do with\nthe images that are malignant (cancer), but not of the class you want to focus\non? Are there images of low quality? Etc. You are allowed to search for and add\nother public dataset, to this set of images.",
      "metadata": {
        "tags": [],
        "cell_id": "00013-0410f06b-5a01-494d-a1df-0ac880c34e77",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "markdown",
      "source": "##### Description of Data: \nThe data includes 150 images of skin lesions and then another 150 images of the same images in segmentations, whereby the image is zoomed in. Besides this the data also includes the Superpixel of some of the images. ",
      "metadata": {
        "tags": [],
        "cell_id": "00014-61812bf2-357a-4ef1-80ff-42c7d71cd030",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00015-84749028-f474-436f-88a2-a5d8cd2730db",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "a63a4e0a",
        "execution_millis": 7,
        "execution_start": 1619174018844,
        "output_cleared": true,
        "deepnote_cell_type": "code"
      },
      "source": "# Loading the data into a dataframe and classifying based on class\nimage_info = pd.read_csv(\"../data/example_ground_truth.csv\")\ncancer_free = image_info[(image_info['melanoma']== 0) & (image_info['seborrheic_keratosis']==0)]\nmelanoma = image_info[image_info['melanoma'] == 1]\nkeratosis = image_info[image_info['seborrheic_keratosis']==1]\n\n#image_info\nprint(\"image_info: {0}, cancer_free: {1}, melanoma: {2}, keratosis: {3}\"\n.format(image_info.shape, cancer_free.shape, melanoma.shape, keratosis.shape))\n",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00018-c377c34b-1394-4c65-8ea4-7bf20ac5700f",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "e49fd9d5",
        "execution_millis": 6,
        "execution_start": 1619174018845,
        "output_cleared": true,
        "deepnote_cell_type": "code"
      },
      "source": "# put keratosis image id's into a list to use later\nlist_keratosis = []\nfor i in keratosis[\"image_id\"]:\n    list_keratosis.append(i)\n\n# deleting the keratosis images in the dictionary PICTURES\n# length of dictiionary has changed from 357 to 275 images\nfor i in list_keratosis:\n    n = (i + '.jpg')\n    x = (i + '_segmentation.png')\n    y = (i + '_superpixels.png')\n    if n in PICTURES:\n        PICTURES.pop(n)\n    if x in PICTURES:\n        PICTURES.pop(x)\n    if y in PICTURES:\n        PICTURES.pop(y)\n\n#now we remove the superpixels\nsuper_pixels = []\n\nfor i in PICTURES:\n   if '_superpixels.png' in i:\n        super_pixels.append(i)\n\nfor i in super_pixels:\n    PICTURES.pop(i)\n\nprint(len(PICTURES))",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "## Checking for duplicates",
      "metadata": {
        "tags": [],
        "cell_id": "00013-853c5f7f-f4ec-43e4-84df-c7aff94508cd",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00017-ae5083f3-244f-42b5-ae93-ee0e6a7c3efa",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "72802f34",
        "execution_millis": 24,
        "output_cleared": true,
        "execution_start": 1619174018846,
        "deepnote_cell_type": "code"
      },
      "source": "\"\"\" First we check for duplicates\"\"\"\n\n#Checks for duplicated image IDs in image_info\nimage_id = set()\nnot_unique_id = 0\nfor i in image_info['image_id']:\n    if i not in image_id:\n        image_id.add(i)\n    else:\n        not_unique += 1\nprint('Number of duplicates image id: {0}'.format(not_unique_id))\n\n#Checks that there is no duplicates in the pictures\nimage_unique = set()\nnot_unique_image = 0\nfor i in PICTURES:\n    if i not in image_unique:\n        image_unique.add(i)\n    else:\n        not_unique_image += 1\nprint('Number of duplicates images: {0}'.format(not_unique_image))\n\n\"\"\"Then we checks that all ID's has a corresponding image, and vice versa\"\"\"\n\n# cancer free and melanoma image id's is loaded into sets\ncf = set(i for i in cancer_free['image_id'])\nmel = set(i for i in melanoma['image_id'])\n\nno_image = set()\n\n#Checks that all IDs in image info is in example folders\nfor i in cf:\n    n = (i + '.jpg')\n    if n not in PICTURES:\n        no_image.add(i)\n\nfor i in mel:\n    n = (i + '.jpg')\n    if n not in PICTURES:\n        no_image.add(i)\n\nprint('No image: {0}'.format(len(no_image)))\n\n#Checks that all pictures in example image folder has a image ID in image_info\nno_ID = set()\n\nfor i in PICTURES:\n    x = i[0:12] #The first 12 characters is the ID\n    if x not in image_id :\n        no_ID.add(i)\nprint('No ID in image_info: {0}'.format(len(no_ID)))\n",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "## Cleaning the Data\n\nIn the following cell the dataset of images is cleaned for the following three criteria:\n\n- Resolution\n- Blurriness/Sharpness\n- Contrast\n\nThe images that do not fit the criteria are removed from the image dictionary.",
      "metadata": {
        "tags": [],
        "cell_id": "00015-ba653751-9f53-4716-963d-7d468d77ea66",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00016-b9b040eb-ae19-492a-960c-8ac3328e3b37",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "fbc11e10",
        "execution_millis": 40428,
        "output_cleared": true,
        "execution_start": 1619174018864,
        "deepnote_cell_type": "code"
      },
      "source": "## Checking RESOLUTION\nsd = 600*450\nlow_quality_pictures(sd, PICTURES)",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00021-c1068cec-c556-41e4-8ade-fed311c7d9db",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "3a5cbd3a",
        "execution_millis": 111587,
        "execution_start": 1619174059279,
        "output_cleared": true,
        "deepnote_cell_type": "code"
      },
      "source": "## Checking BLURRINESS/SHARPNESS\nbluriness(PICTURES)",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "Now we will check the colour quality by checking the contrast level.\n\nTo check the contrast of an image we use the function is_low_contrast from the library skimage.exposure. \n\nhttps://scikit-image.org/docs/dev/api/skimage.exposure.html#re0c68370bb9d-1",
      "metadata": {
        "tags": [],
        "cell_id": "00020-cb46c441-634c-4723-800c-9059397bd401",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00023-3084839f-f822-49fd-809d-955e76e02295",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "f0e4c5f6",
        "execution_millis": 96032,
        "execution_start": 1619174170858,
        "output_cleared": true,
        "deepnote_cell_type": "code"
      },
      "source": "## Checking CONTRAST\ncontrast(PICTURES)",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "## External Data",
      "metadata": {
        "tags": [],
        "cell_id": "00024-4f1837d3-3188-4a6f-9482-6a5d23ee419d",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "markdown",
      "source": "First we load the data and clean it with the same criteria used on the previous data in the dictionary named PICTURES.",
      "metadata": {
        "tags": [],
        "cell_id": "00023-c6cd88f8-54da-4e77-960a-9eb0d4faa594",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00024-779dab04-cba9-4ef8-9e6c-012a92697cf3",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "97260ea9",
        "execution_millis": 10,
        "execution_start": 1619174266890,
        "output_cleared": true,
        "deepnote_cell_type": "code"
      },
      "source": "# First we make the path to the data\nPATH = {}\nPATH[\"external data\"] =\"../external_data/external_data\"\n\n#Then we load the path for all the diffirent as keys to their names.\nEXTERNAL = {}\nfor path, subdirs, files in os.walk(PATH[\"external data\"]):\n    for picture in files:\n        # Making sure that we exclude the .csv from the dictionary, to only include images (ie. png and jpg files)\n        if not str(picture).count(\".csv\", (len(picture) - 4),len(picture)):\n            EXTERNAL[picture] = os.path.normpath(os.path.join(path, picture))\n\nEXTERNAL.pop('.DS_Store')\nprint(len(EXTERNAL))\n\n# Loading the data into a dataframe and classifying based on class\nexternal_image_info = pd.read_csv(\"../external_data/ISIC-2017_Training_Part3_GroundTruth.csv\")\nexternal_cancer_free = external_image_info[(external_image_info['melanoma']== 0) & (external_image_info['seborrheic_keratosis']==0)]\nexternal_melanoma = external_image_info[external_image_info['melanoma'] == 1]\nexternal_keratosis = external_image_info[external_image_info['seborrheic_keratosis']==1]\n\n#image_info\nprint(\"image_info: {0}, cancer_free: {1}, melanoma: {2}, keratosis: {3}\"\n.format(external_image_info.shape, external_cancer_free.shape, external_melanoma.shape, external_keratosis.shape))",
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "The external data is checked for duplicates",
      "metadata": {
        "tags": [],
        "cell_id": "00025-352a99a4-000d-4500-a188-6507a265f6d4",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00026-e19c90c8-3ab1-4f26-8803-56b13a02f610",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "acaa4adf",
        "execution_millis": 28,
        "execution_start": 1619174266896,
        "output_cleared": true,
        "deepnote_cell_type": "code"
      },
      "source": "#Checks for duplicated image IDs in image_info\nimage_id = set()\nnot_unique_id = 0\nfor i in external_image_info['image_id']:\n    if i not in image_id:\n        image_id.add(i)\n    else:\n        not_unique += 1\nprint('Number of duplicates image id: {0}'.format(not_unique_id))\n\n#Checks that there is no duplicates in the pictures\nimage_unique = set()\nnot_unique_image = 0\nfor i in EXTERNAL:\n    if i not in image_unique:\n        image_unique.add(i)\n    else:\n        not_unique_image += 1\nprint('Number of duplicates images: {0}'.format(not_unique_image))\n\n\"\"\"Then we checks that all ID's has a corresponding image, and vice versa\"\"\"\n\n# cancer free and melanoma image id's is loaded into sets\nmel = set(i for i in external_image_info['image_id'])\n\nno_image = set()\n\n#Checks that all IDs in image info is in example folders\nfor i in mel:\n    n = (i + '.jpg')\n    if n not in EXTERNAL:\n        no_image.add(i)\n\nprint('No image: {0}'.format(len(no_image)))\n\n#Checks that all pictures in example image folder has a image ID in image_info\nno_ID = set()\n\nfor i in EXTERNAL:\n    x = i[0:12] #The first 12 characters is the ID\n    if x not in image_id:\n        no_ID.add(i)\n\nprint('No ID in image_info: {0}'.format(len(no_ID)))",
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "External data is checked for resolution quality, blurriness, and contrast quality",
      "metadata": {
        "tags": [],
        "cell_id": "00027-fe821e55-5538-4a72-adcd-b2dd2f6c3bb3",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00028-6061afdf-9563-49b0-87d0-b7a3e41ad277",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "5898427d",
        "execution_millis": 17094,
        "execution_start": 1619174266919,
        "output_cleared": true,
        "deepnote_cell_type": "code"
      },
      "source": "sd = 720 * 480\nlow_quality_pictures(sd, EXTERNAL)",
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00030-330fe4a3-9649-4faa-addd-af32302c954a",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "e9c047f",
        "execution_millis": 54788,
        "execution_start": 1619174283998,
        "output_cleared": true,
        "deepnote_cell_type": "code"
      },
      "source": "bluriness(EXTERNAL)",
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00031-eef1bfe4-86b4-4d67-90fb-2fecd034c20a",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "c412d8bb",
        "execution_millis": 39993,
        "execution_start": 1619174338809,
        "output_cleared": true,
        "deepnote_cell_type": "code"
      },
      "source": "contrast(EXTERNAL)",
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "Now the external data is seperated 50/50 so that 50% can be used to test the model again, and the other 50% can provide the results needed.",
      "metadata": {
        "tags": [],
        "cell_id": "00029-a616c2ec-3762-4221-97c0-e90e8d64678e",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00033-ec8e3b13-0fc7-43b6-b31f-4c4db0b7b70a",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "2d16b044",
        "execution_millis": 70,
        "execution_start": 1619174378802,
        "output_cleared": true,
        "deepnote_cell_type": "code"
      },
      "source": "x = [i for i in external_melanoma['image_id'] ]\nmelanoma_dict = {}\n\n\nfor key, value in EXTERNAL.items():\n    if key[0:12] in x:\n        melanoma_dict[key] = value\n\ny = [i for i in external_cancer_free['image_id'] ]\ncancer_free_dict = {}\n\nfor key, value in EXTERNAL.items():\n    if key[0:12] in y:\n        cancer_free_dict[key] = value\n\n        \nexternal_melanoma['mask'] = external_melanoma['image_id']+'_segmentation.png'\nexternal_melanoma['raw'] = external_melanoma['image_id']+'.jpg'\nexternal_melanoma\n# melonoma_way = pd.DataFrame.from_dict(melanoma_dict)\n# melonoma_way",
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "# Task 1: Implement Two Features\nChoose one of the ABC (Asymetry, Border or Color) features and implement a function to measure it for one\nimage. While you are doing this, you might want to create “toy” images where\nyou already know the results, for example a circle should be less asymmetric\nthan an ellipse, etc.\nOnce you are satisfied with your implementations, run them on all your\nimages, and examine the feature distributions for each class, for example using\nscatter plots. Do you see differences between the classes?",
      "metadata": {
        "tags": [],
        "cell_id": "00014-bd3fff0c-78b3-4120-b6dd-c94f2ef74d8f",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "markdown",
      "source": "## Asymmetry",
      "metadata": {
        "tags": [],
        "cell_id": "00020-f1da71f7-e40c-4d42-8d63-e3bcad4b1d33",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00029-d3047c58-4b6d-4840-8c50-9daba3e7688f",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "afccffe9",
        "execution_millis": 3,
        "execution_start": 1619174378849,
        "output_cleared": true,
        "deepnote_cell_type": "code"
      },
      "source": "def test_asymmetry(mask):\n\n    x_min, x_max, y_min, y_max = get_mask_size(mask)\n\n    mask_cropped = mask[y_min:y_max, x_min:x_max]\n\n    x_half = (x_max - x_min) / 2 # Gives us the middle \n\n    if x_half.is_integer():\n        mask_x_half_left = mask_cropped[:, :int(x_half)]\n        mask_x_half_right = mask_cropped[:, int(x_half):]\n    else:\n        mask_x_half_left = mask_cropped[:, :int(x_half)+1]\n        mask_x_half_right = mask_cropped[:, int(x_half):]\n\n    mask_x_half_right_flipped = np.fliplr(mask_x_half_right)\n\n    x_diff = mask_x_half_left - mask_x_half_right_flipped\n\n    # Fold in half y-axis\n    y_half = (y_max - y_min) / 2 # Gives us the middle \n\n    if y_half.is_integer():\n        mask_y_half_left = mask_cropped[:int(y_half), :]\n        mask_y_half_right = mask_cropped[int(y_half):, :]\n    else:\n        mask_y_half_left = mask_cropped[:int(y_half)+1, :]\n        mask_y_half_right = mask_cropped[int(y_half):, :]\n\n\n    mask_y_half_right_flipped = np.flipud(mask_y_half_right)\n\n    y_diff = mask_y_half_left - mask_y_half_right_flipped\n\n    # Calculing diff\n\n    gray1 = np.count_nonzero(x_diff == 0)\n    non_gray1 = np.count_nonzero(x_diff)\n\n    score_x = non_gray1/gray1 * 100\n\n    gray1 = np.count_nonzero(y_diff == 0)\n    non_gray1 = np.count_nonzero(y_diff)\n\n    score_y = non_gray1/gray1 * 100\n\n    return score_x if score_x > score_y else score_y",
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "## Border",
      "metadata": {
        "tags": [],
        "cell_id": "00022-15828be1-33a6-4355-9f5a-6edd1d958035",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00023-424b25a0-aca6-4b58-a63c-9fce627ad9f4",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "893bf8ec",
        "execution_millis": 8,
        "execution_start": 1619174378855,
        "output_cleared": true,
        "deepnote_cell_type": "code"
      },
      "source": "def find_border(mask):\n    \"\"\"Returns a ratio between the surcumfrance and the area of a mask. \n    It returns 0 for a perfect circle, and increasingly higher returns for larger \n    surcomfrance compared with area.\"\"\"\n    # Using the fact that all values within the area of the mask is 1, \n    # the area is equal to the sum of the mask\n    ones = np.sum(mask)\n    # Applying a gausian border to find the surcumfrance\n    border = filters.difference_of_gaussians(mask,1) \n    # Reducing the size of the border.\n\n    border = np.where((border < -0.01) & (border > 0.01), 1, border)\n    border = np.where(border < 0.01 , 0, border)\n\n\n    surcumfrance = np.sum(border)\n\n    #plt.imshow(border, cmap='gray')\n\n    Compactness = surcumfrance**2/ones*12\n\n\n    return(Compactness)\n\n# Making Test-cases to test that the function returns higher value for less compacness\n# and that the score is independent of size of image.\n# test_square = np.pad(np.ones((100,200)), pad_width = 5, constant_values=0)\n# test_big_square = np.pad(np.ones((1000,2000)), pad_width = 5, constant_values=0)\n# find_border(test_big_square)\n# find_border(test_square)\n\n# Idea from https://stackoverflow.com/questions/10031580/how-to-write-simple-geometric-shapes-into-numpy-arrays\n# xx, yy = np.mgrid[:200, :200]\n\n# circle = (xx - 100) ** 2 + (yy - 100) ** 2\n# circle1 = np.where(circle < 1500, 1, circle)\n# circle1 = np.where(circle1 > 1, 0, circle1)\n# circle2 = np.where(circle < 1850, 1, circle)\n# circle2 = np.where(circle2 > 1, 0, circle2)\n# find_border(circle1)\n# find_border(circle2)\n",
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "## Colour",
      "metadata": {
        "tags": [],
        "cell_id": "00024-5f533f11-966c-441c-b586-77e89ff6601b",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00022-1c9ba73c-3de2-4286-ac65-b2ad43293398",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "9dabff37",
        "execution_millis": 34,
        "execution_start": 1619174378873,
        "output_cleared": true,
        "deepnote_cell_type": "code"
      },
      "source": "def test_color2(image, mask):\n    def sp_idx(s, index = True):\n        u = np.unique(s)\n        return [np.where(s == i) for i in u]\n    \n    # Have to do this in order for skimage label2rgb to work properly\n    mask = img_as_float(mask[::2, ::2])\n    image = img_as_float(image[::2, ::2])\n\n    segments = slic(image, n_segments= 20, compactness=3,sigma= 5, max_iter=10, mask=mask, convert2lab=True)\n\n    blended_colors = label2rgb(segments, image, kind=\"avg\", bg_label=0) # returns RGB floats / RGB Normalized \n    # To convert the normalized RGB back to RGB, we have to multiply the colour channel with 255 and round.\n\n    # The list contains information of the x and y coordinates that correspond with each segment.\n    superpixel_list = sp_idx(segments)\n\n    colours = []\n\n    # Distance from this should be max 10.\n    general_light_skin_colour = (255,224,189)\n    general_light_skin_threshold = 10\n    general_light_skin_hsp_max = 240\n\n    light_skin_colour = None\n    light_skin_colours_hsp = 0\n    not_skin_colour_threshold = 15\n\n    darkest_colour = None\n    darkest_colours_hsp = 255\n\n    # Skip the first entry since it contains the size of the image. \n    for segment in range(1,len(superpixel_list)):\n        # Since we are getting all the x-coordinates and y-coordinates.\n        # We can just pick one of the x and y coordinates. It doesn't matter which one, since they have the same colour.\n        #                            x  x_0\n        x = superpixel_list[segment][0][0]\n        #                            y  y_0\n        y = superpixel_list[segment][1][0]\n\n        r = round(blended_colors[x][y][0] * 255)\n        g = round(blended_colors[x][y][1] * 255)\n        b = round(blended_colors[x][y][2] * 255)\n        \n        colours.append((r,g,b))\n\n        distance = math.sqrt(((r - general_light_skin_colour[0])) ** 2 + ((g - general_light_skin_colour[1])) ** 2 + ((b - general_light_skin_colour[2])) ** 2)\n        # hsp formula http://alienryderflex.com/hsp.html\n        hsp = math.sqrt(0.299 * (r ** 2) + 0.587 * (g ** 2) + 0.114 * (b ** 2))\n        if hsp > light_skin_colours_hsp and (distance < general_light_skin_threshold or hsp < general_light_skin_hsp_max):\n            light_skin_colours_hsp = hsp\n            light_skin_colour = (r,g,b)\n\n    for r,g,b in colours:\n        # Remove the outer bounds of the lesion - to similate removing the skin colour.\n        # Formular to calculate how close the 2 rgb colours are to eachother.\n        distance = math.sqrt(((r - light_skin_colour[0])) ** 2 + ((g - light_skin_colour[1])) ** 2 + ((b - light_skin_colour[2])) ** 2)\n        if distance > not_skin_colour_threshold:\n            # Find darkest colour\n            hsp = math.sqrt(0.299 * (r ** 2) + 0.587 * (g ** 2) + 0.114 * (b ** 2))\n            if hsp < darkest_colours_hsp:\n                darkest_colours_hsp = hsp\n                darkest_colour = (r,g,b)\n\n    average_colour = []\n    counter = 0\n    current_average_colour = 0\n\n    # Remove skin colour\n    # There are 3 channels in RGB, and to get the average we square each channels colors and add them to together to get the average.\n    for i in range(0,3):\n        for index in range(len(colours)):\n            current_average_colour += colours[index][i] ** 2\n            counter += 1\n        average_colour.append(round(math.sqrt(current_average_colour/counter)))\n\n    # Calculate the distance between the average colour and the highest colour\n    distance = math.sqrt(((average_colour[0] - darkest_colour[0])) ** 2 + ((average_colour[1] - darkest_colour[1])) ** 2 + ((average_colour[2] - darkest_colour[2])) ** 2)\n\n    # High value is bad\n    return distance\n",
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "# Task 2: Predict the diagnosis\nSplit your data so that you are have training data and hold-out test data. Use\nthe training data to train different classifiers and investigate their parameters.\nOnce you made a choice, evaluate your classifier on the hold-out test data. Think\nof different metrics you can use, and different ways to present your results.",
      "metadata": {
        "tags": [],
        "cell_id": "00015-e5ac7833-d133-44a4-9de5-648399a98b3a",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "markdown",
      "source": "## Preparing machine learning\nThe data is split into training and the data that will be learned on, and the features are extracted",
      "metadata": {
        "tags": [],
        "cell_id": "00026-5d34e33a-9866-4ee6-baa2-c874e005a231",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00051-c0c140c1-5781-414d-b813-0646713e08b8",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "e6b48389",
        "execution_millis": 0,
        "execution_start": 1619174378907,
        "output_cleared": true,
        "deepnote_cell_type": "code"
      },
      "source": "# Making a set with all the relevant photo-id's\nmelonoma_set = set()\nfor key in melanoma_dict:\n    melonoma_set.add(key[:12])\n\nhealth_set = set()\nfor key in cancer_free_dict:\n    health_set.add(key[:12])\n",
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00051-ec4762db-c1a7-4da4-b11f-74741c081d8e",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "9701ac89",
        "execution_millis": 2,
        "execution_start": 1619174378907,
        "output_cleared": true,
        "deepnote_cell_type": "code"
      },
      "source": "### Extracting the features\nfreature_extract = False # Set this as True to extract features for all photoes.\nif freature_extract:\n    melanoma_list = [] \n    for picture in melonoma_set:\n        try:\n            test_picture = melanoma_dict[picture+\".jpg\"]\n            test_mask = melanoma_dict[picture+\"_segmentation.png\"]\n            #print(test_picture)\n            # Load in the mask and picture\n            temp = []\n            mask = plt.imread(test_mask)\n            raw_pict = plt.imread(test_picture)\n            # Finding the boundaries of the mask.\n            x_min, x_max, y_min, y_max = get_mask_size(mask)\n            # \n            if x_min > 5:\n                mask = mask[:, x_min-3:]\n                raw_pict = raw_pict[:, x_min-3:]\n            if y_min > 5:\n                mask = mask[y_min-3:,:]\n                raw_pict = raw_pict[y_min-3:,:]    \n            if x_max < mask.shape[1]:\n                mask = mask[:,:x_max+3]\n                raw_pict = raw_pict[:,:x_max+3]\n            if  y_max < mask.shape[0]:\n                mask = mask[:y_max+3,:]\n                raw_pict = raw_pict[:y_max+3,:]\n            # Making the feature-extraction on the 3 featurs\n            temp.append(test_asymmetry(mask))\n            temp.append(find_border(mask))\n            temp.append(test_color2(raw_pict, mask))\n            # Adding the data of the picture to the overall list.\n            melanoma_list.append(temp)\n        except:\n            pass\n        \n    healthy_list = []\n    for picture in health_set:\n        try: \n\n            test_picture = cancer_free_dict[picture+\".jpg\"]\n            test_mask = cancer_free_dict[picture+\"_segmentation.png\"]\n            #print(test_picture)\n            # Load in the mask and picture\n            temp = []\n            mask = plt.imread(test_mask)\n            raw_pict = plt.imread(test_picture)\n            # Finding the boundaries of the mask.\n            x_min, x_max, y_min, y_max = get_mask_size(mask)\n            # Only applying the border if the \n            if x_min > 5:\n                mask = mask[:, x_min-5:]\n                raw_pict = raw_pict[:, x_min-5:]\n            if y_min > 5:\n                mask = mask[y_min-5:,:]\n                raw_pict = raw_pict[y_min-5:,:]    \n            if x_max < mask.shape[1]:\n                mask = mask[:,:x_max+5]\n                raw_pict = raw_pict[:,:x_max+5]\n            if  y_max < mask.shape[0]:\n                mask = mask[:y_max+5,:]\n                raw_pict = raw_pict[:y_max+5,:]\n            # Making the feature-extraction on the 3 featurs\n            temp.append(test_asymmetry(mask))\n            temp.append(find_border(mask))\n            temp.append(test_color2(raw_pict, mask))\n            # Adding the picture to the overall.\n            healthy_list.append(temp)\n\n        except:\n            pass\n",
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00047-90e324ba-4075-4859-bb06-5ee0fdb68cc1",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "7bd8b71d",
        "execution_millis": 6,
        "execution_start": 1619174378911,
        "output_cleared": true,
        "deepnote_cell_type": "code"
      },
      "source": "# Saving the  features in an csv-file.\nif freature_extract:\n    melanoma_df = pd.DataFrame.from_records(melanoma_list, columns = (\"Asymmetry\" ,\"compactness\", \"colour\"))\n    melanoma_df.to_csv(\"../data/melanoma_data2.csv\")\n    df_test= pd.DataFrame.from_records(healthy_list, columns = (\"Asymmetry\",\"Border\", \"Colour\"))\n    df_test.to_csv(\"../data/health_df2.csv\")",
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "### Making the test\nWith the data gathered, we triain the model. First the data is loaded and split into two groups",
      "metadata": {
        "tags": [],
        "cell_id": "00041-570e94c0-21ee-4484-ae85-11aa5b40f524",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00058-1f67d018-182e-47d4-8da8-dfa86c0829d8",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "c3badca3",
        "execution_millis": 64,
        "execution_start": 1619174378919,
        "output_cleared": true,
        "deepnote_cell_type": "code"
      },
      "source": "# Loading in the extracted features in in a dataframe\ndf_healthy = pd.read_csv(\"../data/health_df2.csv\")\ndf_ill = pd.read_csv(\"../data/melanoma_data2.csv\")\ndf_healthy\n# Removing the previous index.\ndf_healthy = df_healthy.drop(labels = \"Unnamed: 0\", axis= 1)\ndf_ill = df_ill.drop(labels= \"Unnamed: 0\", axis = 1)\n# Adding weather cancer is or is not pressent in the photo\ndf_healthy['melanoma'] = 0\ndf_ill['melanoma'] = 1\n# Renaming the values so it is the same for both dataframes\ndf_ill = df_ill.rename(columns={\"compactness\": \"Border\", \"colour\": \"Colour\"})\n# Creating the traning-dataset as the first 160 sick and healthy. \ndf_training = df_healthy[0:160]\ndf_training = df_training.append(df_ill[0:160])\n# Creating the test-set in the same way.\ndf_verification = df_healthy[160:]\ndf_verification = df_verification.append(df_ill[160:])\ndf_verification",
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00052-de85581c-94f4-4903-8b88-0ae15334173e",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "2451cc21",
        "execution_millis": 2,
        "execution_start": 1619174378974,
        "output_cleared": true,
        "deepnote_cell_type": "code"
      },
      "source": "# Let's scale the features\n#Fit scaler on our data\nscaler = preprocessing.StandardScaler().fit(df_training[[\"Asymmetry\",\"Border\", \"Colour\"]])\n\n#Apply to data itself\ndf_train = scaler.transform(df_training[[\"Asymmetry\",\"Border\", \"Colour\"]])\ndf_test = scaler.transform(df_verification[[\"Asymmetry\",\"Border\", \"Colour\"]])\n",
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00053-d0da7b32-8367-459a-bb0e-d9bd713b4397",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "31c2af16",
        "execution_millis": 32,
        "execution_start": 1619174378976,
        "output_cleared": true,
        "deepnote_cell_type": "code"
      },
      "source": "\n# Save the data in two dataframes\ndf = pd.DataFrame(df_train, columns = [\"Asymmetry\",\"Border\", \"Colour\"])\ndf['illens'] = df_training['melanoma'].to_list()\n\ndf_test = pd.DataFrame(df_test, columns = [\"Asymmetry\",\"Border\", \"Colour\"])\ndf_test['illens'] = df_verification['melanoma'].to_list()\ndf_test\n",
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "#### Visualizing the data",
      "metadata": {
        "tags": [],
        "cell_id": "00055-8985dc3b-90f7-42dd-ae4a-eb97b584b8e4",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00063-7327d234-e1d6-4397-ab1b-44891e865a42",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "e9b60739",
        "execution_millis": 1670,
        "execution_start": 1619174379000,
        "output_cleared": true,
        "deepnote_cell_type": "code"
      },
      "source": "# Making scatterplots for all 2-dimentional posibilities.\nsns.pairplot(df[[\"Asymmetry\",\"Border\", \"illens\"]], hue=\"illens\", size=3,diag_kind=\"hist\")",
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00064-a5877244-454f-43eb-8317-99897769a6b0",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "ba8481c5",
        "execution_millis": 1394,
        "execution_start": 1619174380665,
        "output_cleared": true,
        "deepnote_cell_type": "code"
      },
      "source": "sns.pairplot(df[[\"Asymmetry\",\"Colour\", \"illens\"]], hue=\"illens\", size=3,diag_kind=\"hist\")",
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00065-c557f279-6e1d-40a0-a416-0ddc9470a2ab",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "3679acf8",
        "execution_millis": 1731,
        "execution_start": 1619174382066,
        "output_cleared": true,
        "deepnote_cell_type": "code"
      },
      "source": "sns.pairplot(df[[\"Border\",\"Colour\", \"illens\"]], hue=\"illens\", size=3,diag_kind=\"hist\")",
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "#### Predicting via KNN",
      "metadata": {
        "tags": [],
        "cell_id": "00059-de66d6f3-9960-49b3-bc14-d5343be003e3",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00056-72dc3e81-4dc7-430b-b6ff-d89f178f0040",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "6a7ca1c1",
        "execution_millis": 627,
        "execution_start": 1619174383849,
        "output_cleared": true,
        "deepnote_cell_type": "code"
      },
      "source": "# Creating a list of predictions, and testing the accuracy of the predictions\nacc_list = []\nacc_dict = {}\nfor i in range(1,60): #Testing the accuracy when k = i\n    acc_list.append(accuracy_score(df_test['illens'], make_knn_prediction(i)))\n# Plotting KNN's performanc\nfig = plt.figure(figsize=(4, 3))\naxes = fig.add_axes([0, 0, 1.5, 1])\naxes.plot(range(1,60), acc_list)\naxes.set_xlabel('Value of k')\naxes.set_ylabel('Test accuracy')\naxes.set_title('Illnes classification accuracy of KNN for diffirent values of k')\naxes.grid(True)",
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "### Predicting using Gausian Process clasifier",
      "metadata": {
        "tags": [],
        "cell_id": "00063-45ee07bd-b7f6-4296-9dd4-2191eb542908",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00063-3629a235-a070-4ced-9b39-336ab65676c7",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "95801da0",
        "execution_millis": 552,
        "execution_start": 1619174384479,
        "output_cleared": true,
        "deepnote_cell_type": "code"
      },
      "source": "gaus_predict = pd.DataFrame(columns = [ \"true_positive\", \"false_positive\", \"true_negative\", \"false_negative\"])\nfor i in [1, 2, 3]: # Testing the model after 1, 2 and 3 itterations\n    gaus = GaussianProcessClassifier(max_iter_predict = i).fit(X = df[['Asymmetry','Border', 'Colour']], y = df['illens'])\n    #After fitting the classifier, using the classifier to predict our test data.\n    guess = gaus.predict(df_test[['Asymmetry','Border', 'Colour']])\n    true_positive, false_positive, true_negative, false_negative = accuracy_matrix(guess, df_test['illens'])\n    gaus_predict.loc[i] = [true_positive, false_positive,  true_negative, false_negative]\ngaus_predict\n\nax = sns.heatmap(gaus_predict)\nax.set_title(\"Heatmap of precicion by Gaussian process classification for diffirent itterations\")\nax.set_ylabel(\"iterations\");\n",
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "# Task 3: open question\nUse the data to formulate, motivate, answer, and discuss another research question of your choice. You may use other data or features here, that we did not\ncover",
      "metadata": {
        "tags": [],
        "cell_id": "00016-a34d0ca6-4ad9-47c7-9629-e46a064730fa",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "markdown",
      "source": "### Does decreasing the dimentionality increase the performance of the model?",
      "metadata": {
        "tags": [],
        "cell_id": "00071-49e65721-a56a-4da9-b755-c9f16cad4b2f",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00072-40fce6c8-9eb5-4349-9b67-a2515eb1ae76",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "aefc7454",
        "execution_millis": 672,
        "execution_start": 1619174385036,
        "output_cleared": true,
        "deepnote_cell_type": "code"
      },
      "source": "# First the performance of the model is found when only having two features \ntwo_dimentional_factors = [['Asymmetry','Border'], ['Border', 'Colour'], ['Asymmetry', 'Colour']]\ni = 0\ntwo_factor_predict = pd.DataFrame(columns = [ \"true_positive\", \"false_positive\", \"true_negative\", \"false_negative\"])\nfor factors in two_dimentional_factors: \n    i += 1 # Getting the predictions for every pair.\n    gaus = GaussianProcessClassifier(max_iter_predict = 5).fit(X = df[factors], y = df['illens'])\n    guess = gaus.predict(df_test[factors])\n    true_positive, false_positive, true_negative, false_negative = accuracy_matrix(guess, df_test['illens'])\n    two_factor_predict.loc[i] = [true_positive, false_positive,  true_negative, false_negative]\ntwo_factor_predict\n# Plotting the performance in a heatmap\nnames = ('Asymetry and Border', 'Border and Colour', 'Asymetry and Colour')\nax = sns.heatmap(two_factor_predict)\nax.set_title(\"Heatmap of precicion by Gaussian process classification for diffirent itterations\")\nax.set_ylabel(\"Combination of features\")\nax.set_yticks(range(3))\nax.set_yticklabels(names);",
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00073-2bf287a3-0c51-4c27-98d3-d2cf6c161cd4",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "9c5ba2e4",
        "execution_millis": 18,
        "execution_start": 1619174385718,
        "output_cleared": true,
        "deepnote_cell_type": "code"
      },
      "source": "two_factor_predict #Printing the performance of the model",
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00073-c883bebc-b0c1-41a9-ba78-fa518f647205",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "9b846a58",
        "execution_millis": 16,
        "execution_start": 1619174385731,
        "output_cleared": true,
        "deepnote_cell_type": "code"
      },
      "source": "diffirence_in_performance = two_factor_predict - gaus_predict.iloc[2]\ndiffirence_in_performance # Comparing each model with the 3-dimentional model. ",
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "### Reducing dimentionality by utilizing PCA on shape-messuring data-points.",
      "metadata": {
        "tags": [],
        "cell_id": "00075-118c0399-1305-466f-a394-f2a5bff8d401",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "code",
      "source": "pca = PCA(n_components=1) # Create PCA object\n\npca.fit(df[['Asymmetry','Border']]) # Fith the PCA to our data.\npca_performance = pd.DataFrame(columns = [ \"true_positive\", \"false_positive\", \"true_negative\", \"false_negative\"])\n\n# Applying the PCA to our data.\ndf['shape'] = pca.fit_transform(df[['Asymmetry','Border']])\ndf_test['shape'] = pca.fit_transform(df_test[['Asymmetry','Border']])\n\n# Evaluating the performance, and then comparing the performance, \ngaus = GaussianProcessClassifier(max_iter_predict = 5).fit(X = df[['Colour', 'shape']], y = df['illens'])\nguess = gaus.predict(df_test[['Colour', 'shape']])\ntrue_positive, false_positive, true_negative, false_negative = accuracy_matrix(guess, df_test['illens'])\npca_performance.loc[0] = [true_positive, false_positive,  true_negative, false_negative]\npca_performance.loc[1] = pca_performance.loc[0] - gaus_predict.iloc[2]\npca_performance # The negative prediction becomes better, but positive is 13% worse\n",
      "metadata": {
        "tags": [],
        "cell_id": "00076-81069a3b-4b26-4dc8-b9c7-0b51d29dea78",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "dc4081f2",
        "execution_millis": 165,
        "execution_start": 1619174385764,
        "output_cleared": true,
        "deepnote_cell_type": "code"
      },
      "outputs": [],
      "execution_count": 40
    },
    {
      "cell_type": "markdown",
      "source": "",
      "metadata": {
        "tags": [],
        "cell_id": "00062-027ab979-78d6-4246-bb8c-442a8c4a13a9",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "markdown",
      "source": "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=6c6ff636-1d68-49e2-b04b-ee0d9895f3db' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,PD94bWwgdmVyc2lvbj0iMS4wIiBlbmNvZGluZz0iVVRGLTgiPz4KPHN2ZyB3aWR0aD0iODBweCIgaGVpZ2h0PSI4MHB4IiB2aWV3Qm94PSIwIDAgODAgODAiIHZlcnNpb249IjEuMSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIiB4bWxuczp4bGluaz0iaHR0cDovL3d3dy53My5vcmcvMTk5OS94bGluayI+CiAgICA8IS0tIEdlbmVyYXRvcjogU2tldGNoIDU0LjEgKDc2NDkwKSAtIGh0dHBzOi8vc2tldGNoYXBwLmNvbSAtLT4KICAgIDx0aXRsZT5Hcm91cCAzPC90aXRsZT4KICAgIDxkZXNjPkNyZWF0ZWQgd2l0aCBTa2V0Y2guPC9kZXNjPgogICAgPGcgaWQ9IkxhbmRpbmciIHN0cm9rZT0ibm9uZSIgc3Ryb2tlLXdpZHRoPSIxIiBmaWxsPSJub25lIiBmaWxsLXJ1bGU9ImV2ZW5vZGQiPgogICAgICAgIDxnIGlkPSJBcnRib2FyZCIgdHJhbnNmb3JtPSJ0cmFuc2xhdGUoLTEyMzUuMDAwMDAwLCAtNzkuMDAwMDAwKSI+CiAgICAgICAgICAgIDxnIGlkPSJHcm91cC0zIiB0cmFuc2Zvcm09InRyYW5zbGF0ZSgxMjM1LjAwMDAwMCwgNzkuMDAwMDAwKSI+CiAgICAgICAgICAgICAgICA8cG9seWdvbiBpZD0iUGF0aC0yMCIgZmlsbD0iIzAyNjVCNCIgcG9pbnRzPSIyLjM3NjIzNzYyIDgwIDM4LjA0NzY2NjcgODAgNTcuODIxNzgyMiA3My44MDU3NTkyIDU3LjgyMTc4MjIgMzIuNzU5MjczOSAzOS4xNDAyMjc4IDMxLjY4MzE2ODMiPjwvcG9seWdvbj4KICAgICAgICAgICAgICAgIDxwYXRoIGQ9Ik0zNS4wMDc3MTgsODAgQzQyLjkwNjIwMDcsNzYuNDU0OTM1OCA0Ny41NjQ5MTY3LDcxLjU0MjI2NzEgNDguOTgzODY2LDY1LjI2MTk5MzkgQzUxLjExMjI4OTksNTUuODQxNTg0MiA0MS42NzcxNzk1LDQ5LjIxMjIyODQgMjUuNjIzOTg0Niw0OS4yMTIyMjg0IEMyNS40ODQ5Mjg5LDQ5LjEyNjg0NDggMjkuODI2MTI5Niw0My4yODM4MjQ4IDM4LjY0NzU4NjksMzEuNjgzMTY4MyBMNzIuODcxMjg3MSwzMi41NTQ0MjUgTDY1LjI4MDk3Myw2Ny42NzYzNDIxIEw1MS4xMTIyODk5LDc3LjM3NjE0NCBMMzUuMDA3NzE4LDgwIFoiIGlkPSJQYXRoLTIyIiBmaWxsPSIjMDAyODY4Ij48L3BhdGg+CiAgICAgICAgICAgICAgICA8cGF0aCBkPSJNMCwzNy43MzA0NDA1IEwyNy4xMTQ1MzcsMC4yNTcxMTE0MzYgQzYyLjM3MTUxMjMsLTEuOTkwNzE3MDEgODAsMTAuNTAwMzkyNyA4MCwzNy43MzA0NDA1IEM4MCw2NC45NjA0ODgyIDY0Ljc3NjUwMzgsNzkuMDUwMzQxNCAzNC4zMjk1MTEzLDgwIEM0Ny4wNTUzNDg5LDc3LjU2NzA4MDggNTMuNDE4MjY3Nyw3MC4zMTM2MTAzIDUzLjQxODI2NzcsNTguMjM5NTg4NSBDNTMuNDE4MjY3Nyw0MC4xMjg1NTU3IDM2LjMwMzk1NDQsMzcuNzMwNDQwNSAyNS4yMjc0MTcsMzcuNzMwNDQwNSBDMTcuODQzMDU4NiwzNy43MzA0NDA1IDkuNDMzOTE5NjYsMzcuNzMwNDQwNSAwLDM3LjczMDQ0MDUgWiIgaWQ9IlBhdGgtMTkiIGZpbGw9IiMzNzkzRUYiPjwvcGF0aD4KICAgICAgICAgICAgPC9nPgogICAgICAgIDwvZz4KICAgIDwvZz4KPC9zdmc+' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>",
      "metadata": {
        "tags": [],
        "created_in_deepnote_cell": true,
        "deepnote_cell_type": "markdown"
      }
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "orig_nbformat": 2,
    "deepnote_notebook_id": "e50eb8b2-04a0-4ded-9e69-06ff860d3ad0",
    "deepnote": {},
    "deepnote_execution_queue": []
  }
}